{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be7143f1-b3b1-4391-b461-4db2df017811",
   "metadata": {},
   "source": [
    "# Generating Jupyter Notebooks using Reflection \n",
    "Reflection is a way to question the results of an LLM by the same or a different LLM.\n",
    "With this additional prompting step, we can correct results the LLM might have gotten wrong in the first step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ecf7639-9e30-481a-9ce1-39eb67acbdd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "from IPython.display import Markdown\n",
    "import json\n",
    "from llm_utilities import prompt_scadsai_llm\n",
    "from functools import partial\n",
    "\n",
    "# select the prompt function and model\n",
    "prompt = partial(prompt_scadsai_llm, model=\"deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37648478-a4ff-4778-b663-0811cf780295",
   "metadata": {},
   "source": [
    "## Initial prompting step\n",
    "First, we prompt an LLM as usual. Our example task asks for generating a trivial Jupyter notebook. \n",
    "Jupyter notebooks are files in json format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70f56a0b-0014-4f8d-967a-9f38760ba100",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "[Open notebook](generated_notebook.ipynb)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_notebook = prompt(\"\"\"\n",
    "Write Python code for demonstrating plotting using seaborn with 10 plots.\n",
    "Output it as Jupyter notebook in ipynb/json format. \n",
    "Add explanationory cells in betweeen the code cells.\n",
    "The notebook should contain explanation of how to call the function.\n",
    "Make sure there are line breaks after each code line.\n",
    "\"\"\").strip().strip(\"```json\").strip(\"```\")\n",
    "\n",
    "first_file = \"generated_notebook.ipynb\"\n",
    "with open(first_file, 'w') as file:\n",
    "    file.write(first_notebook)\n",
    "    \n",
    "Markdown(f\"[Open notebook]({first_file})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7b88db-aed7-4a24-a1e5-3e87147cc387",
   "metadata": {},
   "source": [
    "This function can be used to test if the response is valid json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b45f74eb-2e81-40cc-88e2-2b6d75ae6106",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_valid_json(test_string):\n",
    "    import json\n",
    "    try:\n",
    "        json.loads(test_string)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "is_valid_json(first_notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56f42d2-8359-4b0f-bfba-f56a0dedcf15",
   "metadata": {},
   "source": [
    "## Reflection step\n",
    "We now take the output of the first prompt and modify it to make sure it is a Jupyter notebook file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ff17148-a9db-4fea-81af-67dbb59ad5a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "[Open notebook](modified_notebook.ipynb)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_notebook = prompt(f\"\"\"\n",
    "Take the following text and extract the Jupyter \n",
    "notebook ipynb/json from it:\n",
    "\n",
    "{first_notebook}\n",
    "\n",
    "Make sure the output is in ipynb/json format only. No markdown fences please.\n",
    "\"\"\").strip().strip(\"```json\").strip(\"```\")\n",
    "\n",
    "second_file = \"modified_notebook.ipynb\"\n",
    "with open(second_file, 'w') as file:\n",
    "    file.write(second_notebook)\n",
    "    \n",
    "Markdown(f\"[Open notebook]({second_file})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6f10e24-ab74-408e-b551-200ee65ad028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_valid_json(second_notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c2cebd-afe2-469b-9500-6b6b56ac6d8d",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Ask the LLM to produce a more complex example notebook. Try to find the limits of this approach.\n",
    "\n",
    "## Exercise\n",
    "Try different models such as meta-llama/Llama-3.3-70B-Instruct and mistral-7b-q4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697bf8a9-0e60-4ef7-b8ce-f8e0c9fdc44e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6756a2aa-f2f0-4fd2-b736-3bfc3ed2057b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
